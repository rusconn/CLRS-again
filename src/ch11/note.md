# 11 章 ハッシュ表

ハッシュ表は普通の配列の概念の一般化。  
辞書を効率よく実現するデータ構造。  
要素の探索に最悪 $\Theta(n)$ かかるが、妥当な仮定の下では平均 $O(1)$ 。

## 11.1 直接アドレス表

出現する可能性のあるキーの全集合 $U = \lbrace 0,1,\ldots m-1 \rbrace$ がそれほど大きくない場合に有効。  
**直接アドレス表**(direct-address table)と呼ぶ配列 $T$ を用いる。  
配列の各位置を**枠**(slot)と呼ぶ。枠は全集合 $U$ のキーに対応する。

```pseudo
DIRECT-ADDRESS-SEARCH(T, k):
  return T[k]
```

```pseudo
DIRECT-ADDRESS-INSERT(T, x):
  T[x.key] = x
```

```pseudo
DIRECT-ADDRESS-DELETE(T, x):
  T[x.key] = NIL
```

どれも $O(1)$ 時間で走る。  
枠 $k$ が集合内のキー $k$ を持つ要素を指している。 $k$ は重複しないと仮定した。  
集合がキー $k$ を持つ要素を含まなければ $T[k] = \text{NIL}$ である。

この方法には２つの欠点がある

- 全集合 $U$ が非常に大きいときには、記憶領域が足りなくなる
- **実際に格納される**キーの集合が $U$ に比べて小さいとき、記憶領域が無駄になる

（計数ソートに似ているな？）

## 11.2 ハッシュ表

直接アドレス表の欠点を克服するため、ハッシュ表を用いる。  
ハッシュ表を用いると、要素の探索が $O(1)$ であるという特徴を維持したまま、必要な領域を削減できる。  
ただし、直接アドレス法の探索時間は**最悪評価**なのに対し、ハッシュ表の探索時間は**平均時間**。

ハッシュ法ではキー $k$ を持つ要素を枠 $k$ へではなく、 $h(k)$ へ格納する。  
$h$ はキー $k$ から枠を計算するための**ハッシュ関数**(hash function)。
$h$ はキーの全集合 $U$ から**ハッシュ表**(hash table) $T[0..m-1]$ の枠の集合への写像、すなわち

$$
  h: U \rightarrow \lbrace 0,1,\ldots,m-1 \rbrace
$$

であり、普通、ハッシュ表のサイズ $m$ は $U$ のサイズに比べて十分に小さい。  
キー $k$ を持つ要素を枠 $h(k)$ にハッシュ(hash)すると言い、 $h(k)$ をキー $k$ の**ハッシュ値**(hash value)と呼ぶ。  
ハッシュ関数は配列添字の値域を狭め、配列サイズを減少させる。

このアイデアは、同じ枠に複数のキーがハッシュされる可能性があるという欠点を抱えている。  
この状況を**衝突**(collision)と言う。  
衝突を解決するための方法を用意しておく必要がある。  
衝突解決方式として、本節ではチェイン法、第 $11.4$ 節ではオープンアドレス指定法を紹介する。

### チェイン法による衝突解決

**チェイン法**(chaining)では同じ枠にハッシュされたすべての要素を１つの連結リストに置く。  
枠 $j$ に格納するのは $j$ にハッシュされたすべての要素を格納するリストの先頭を指すポインタとする。

```pseudo
CHAINED-HASH-INSERT(T, x):
  x をリスト T[h(x.key)] の先頭に挿入する
```

```pseudo
CHAINED-HASH-SEARCH(T, k):
  リスト T[h(k)] の中からキー k を持つ要素を探索する
```

```pseudo
CHAINED-HASH-DELETE(T, x):
  リスト T[h(x.key)] から x を削除する
```

挿入の最悪実行時間は $O(1)$ である。  
挿入においてキーの重複を考慮するなら、キー x.key を持つ要素を検索する必要があるのでこの限りではない。  
また、双方向連結リストを用いると要素の削除操作を $O(1)$ で実現できる。

### チェイン法を用いるハッシュ法の解析

挿入と削除は $O(1)$ 時間で実行できるとわかるが、探索にかかる時間が不明なので解析する。  
$n$ 個の要素を格納している枠数 $m$ のハッシュ表 $T$ の**負荷率**(load factor) $α$ を $n/m$ で定義する。  
$α$ は１つのチェインに格納されている要素数の平均を意味する。

ハッシュ関数が**単純一様ハッシュ**(simple uniform hashing)（他の要素がどの枠にハッシュされたかとは無関係に、 $m$ 個の枠へ等確率でハッシュする）であると仮定すると、  
要素の探索にかかる時間はハッシュ算出の $O(1)$ 、チェイン探索の $\Theta(\alpha)$ の和である、 $\Theta(1 + \alpha)$ となる。  
枠数が少なくとも要素数に比例すると仮定すると $n = O(m)$ であり、 $\alpha = n/m = O(m)/m = O(1)$ を結論できる。  
つまり、挿入、探索、削除をすべて平均 $O(1)$ 時間で提供できる。

## 11.3 ハッシュ関数

### 優れたハッシュ関数の条件

優れたハッシュ関数は（おおよそ）単純一様ハッシュ仮定を満足する。  
しかし、キーの出現を支配する確率分布が既知であることは稀だから、多くの場合にはこの条件の成否を確かめることはできない。

### キーの自然数としての解釈

ほとんどのハッシュ関数ではキーの全集合を自然数の集合 $\mathbb{N} = \lbrace 0,1,2,\ldots \rbrace$ と仮定する。  
したがって、キーが自然数ではない時には、キーを自然数として解釈する方法が必要になる。  
たとえば、 "pt" は ASCII コードで $p = 112$, $t = 116$ なので、 $10$ 進数の組 $(112,116)$ として解釈できる。  
これを基数 $128$ の整数だと解釈すれば、 $(112\cdot128)+116 = 14452$ となる。

以降、キーは自然数であると仮定する。

## 11.3.1 除算法

ハッシュ関数を生成するための**除算法**(division method)では、キー $k$ を枠数 $m$ で割り、剰余に対応する枠を $k$ に対応させる。

$$
  h(k) = k \bmod m
$$

ハッシュ関数の計算に１つの命令しか必要としないから、除算によるハッシュは極めて高速。

$m$ は $2$ のベキであってはならない。なぜなら、 $m = 2^p$ とすると、 $h(k)$ は $k$ の最下位 $p$ ビットの値になる。  
すべてのビットに依存するようにハッシュ関数を設計するほうが勝る。

$2$ のベキに近くない素数を $m$ とするのは優れた選択であることが多い。  
おおよそ $n = 2000$ 個の文字列を格納する目的で、チェイン法で衝突を解決するハッシュ表を作りたいとする。  
失敗に終わる探索が平均 $3$ 個の要素を検査する必要があることは気にならないので、大きさ $m = 701$ のハッシュ表を割り付ける。  
$m = 701$ を選択した理由は、 $701$ が $2000/3$ に近く、 $2$ のどのベキにも近くない素数だからである。

## 11.3.2 乗算法

ハッシュ関数を生成するための**乗算法**(multiplication method)では２段階でハッシュ関数を計算する。

$$
  h(k) = \lfloor m(kA \bmod 1) \rfloor (0 < A < 1)
$$

「 $kA \bmod 1$ 」は $kA$ の少数部分 $kA - \lfloor kA \rfloor$ を意味する。

$m$ の値がそれほど重要ではないことが乗算法の長所。通常、 $2$ のベキを選択する。  
定数 $A$ をどのように選択しても正しく働くが、ハッシュ関数の良さは $A$ の選択に依存する。  
$\text{Knuth}$ は

$$
  A \approx (\sqrt{5} - 1)/2 = 0.6180339887\ldots
$$

が優れていると述べた。

## 11.3.3 万能ハッシュ法

所謂 HashDOS に対応するため、ハッシュ表に格納されつつあるキーとは**独立**にハッシュ関数を**ランダム**に選択する。  
意図的に同じ枠にハッシュされるキーを選択しても、**万能ハッシュ法**(universal hashing)と呼ばれるこの方針が優れた平均性能を示す。

## 11.4 オープンアドレス指定法

**オープンアドレス指定法**(open addressing)では、すべての要素をハッシュ表に格納する。  
チェイン法のように、表の外部にリストを持ち、そこに要素を格納することはしない。  
したがって、負荷率 $\alpha$ は $1$ を超えない。

オープンアドレス指定法ではポインタを辿る代わりに検査しなくてはならない枠の列を**計算**する。  
ポインタを格納しないことで空いた記憶はハッシュ表に還元され、衝突の減少と検索の高速化が達成される可能性がある。

オープンアドレス指定法を用いて挿入を実行するには、空の枠に出会うまでハッシュ表を次々と**探査**(probe)する。  
枠を探査する順序を決めるために、ハッシュ関数を拡張して第 $2$ 引数として（初期値が $0$ の）探査番号を導入する。

$$
  h: U \times \lbrace 0,1,\ldots,m-1 \rbrace \rightarrow \lbrace 0,1,\ldots,m-1 \rbrace
$$

オープンアドレス指定法では、すべてのキー $k$ について**探査列**(probe sequence)

$$
  \langle h(k,0),h(k,1),\ldots,h(k,m-1)\rangle
$$

は、すべての枠を新しいキーを格納する場所として考慮し、表を完全に埋めるために、 $\langle 0,1,\ldots,m-1 \rangle$ の置換であることが要請される。

挿入の擬似コードは

```pseudo
HASH-INSERT(T, k):
  i = 0
  repeat
    j = h(k, i)
    if T[j] == NIL
      T[j] = k
      return j
    else
      i = i + 1
  until i == m
  error "ハッシュ表オーバーフロー"
```

となる。

キーが削除されないことを前提とした探索はこう。

```pseudo
HASH-SEARCH(T, k):
  i = 0
  repeat
    j = h(k, i)
    if T[j] == k
      return j
    i = i + 1
  until T[j] == NIL または i == m
  return NIL
```

キーの削除を実現する場合、削除された枠に $\text{NIL}$ を入れてしまうと、  
枠が未使用( $= \text{NIL}$ )であることと、使用されたが削除済みであることの区別ができなくなる。  
区別をするために特別な値を用いることでこの問題を解決できるが、探索時間が負荷率 $\alpha$ に依存しなくなってしまう。  
これが、要素を削除する必要があるときにチェイン法が好まれる理由。

次にオープンアドレス指定法に用いられる手法を３つ紹介する。

### 線形探査

通常のハッシュ関数 $h' : U \rightarrow  \lbrace 0,1,\ldots,m-1 \rbrace$ を考える。  
**線形探査法**(linear probing)は、 $i =  0,1,\ldots,m-1$ に対してハッシュ関数

$$
  h(k,i) = (h'(k) + i) \bmod m
$$

を用いる。 $h'$ を **補助ハッシュ関数**(auxiliary hash function)と呼ぶ。  
キー $k$ が与えられたとき、 $T[h'(k)],T[h'(k)+1],\ldots,T[m-1],T[0],T[1],\ldots,T[h'(k)-1]$ と探査する。  
したがって、異なる探査列の個数は $m$ である。

線形探査は簡単に実装できるが、**主クラスタ化**(primary clustering)として知られている深刻な問題が発生する。  
長い区間の枠がすべて使用中になり平均探査時間が悪化する。

### ２次関数探査法

**$2$ 次関数探査法**(quadratic probing)は形式

$$
  h(k,i) = (h'(k)+c_1i + c_2i^2) \bmod m
$$

で表現されるハッシュ関数を用いる。
$h'$ は補助ハッシュ関数、 $c_1,c_2$ は正の補助定数、 $i = 0,1,\ldots,m-1$ である。

この方法は線形探査よりもはるかに良い結果を導くが、ハッシュ表を完全に利用するには $c_1,c_2,m$ を上手に選択する必要がある。  
同じ初期探査位置を持つ $2$ つのキーは同じ探査列を持つので、**副クラスタ化**(secondary clustering)と呼ばれる、やや望ましくない状況が発生する。

異なる探査列の個数は $m$ 。

### ダブルハッシュ法

オープンアドレス指定法に利用できる最良の方法の $1$ つ。  
**ダブルハッシュ法**(double hashing)は形式

$$
  h(k,i) = (h_1(k) + ih_2(k)) \bmod m
$$

で表現されるハッシュ関数を用いる。 $h_1,h_2$ は補助ハッシュ関数。  
探査列はキー $k$ に二重に依存している。

ハッシュ表全体を探索するには、値 $h_2(k)$ はハッシュ表のサイズ $m$ と互いに素でなければならない。  
この条件を実現する便利な方法は、 $m$ を $2$ のベキ乗に取り、常に常に奇数を生成するように $h2$ を生成することである。  
あるいは、 $m$ を素数に取り、常に $m$ 未満の正の数を生成するように $h_2$ を設計する方法もある。

たとえば、 $m$ を素数とし、ハッシュ関数を

- $h_1(k) = k \bmod m$
- $h_2(k) = 1 + (k \bmod m')$

と定めればよい。 $m'$ は $m$ より僅かに小さい数。

$m$ が素数か $2$ のベキのとき、可能な組 $(h_1(k),h_2(k))$ のそれぞれが異なる探査列を生成するので、 $\Theta(n^2)$ 個の探査列が利用できる。

### オープンアドレスハッシュ法の解析

詳細は省くが、一様ハッシュを仮定すると以下が成立する。

- 失敗に終わる探索に必要な探査数の期待値は $1/(1-\alpha)$ 以下
- 挿入するために必要な平均探査回数は高々 $1/(1-\alpha)$
- 成功に至る探査に必要な探査回数の期待値は高々 $\frac{1}{\alpha}\ln\frac{1}{1-\alpha}$

ハッシュ表の半分が埋まっている場合には、成功する探索の探査回数の期待値は $1.387$ 未満、  
ハッシュ表の $90$ パーセントが埋まっている場合でも、探査回数の期待値は $2.559$ 未満となる。

[← 前へ](../ch10/note.md)
